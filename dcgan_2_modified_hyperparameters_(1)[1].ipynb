{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYsJe-OILSXs"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgeCKiCGLYSG"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnRJYqKaLZ7m"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xVTj9BkLfC1"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BASELINE_BATCH_SIZE = 256\n",
        "NEW_BATCH_SIZE = 128\n",
        "NOISE_DIM = 100\n",
        "NEW_NOISE_DIM = 50\n",
        "EPOCHS = [50]\n",
        "BASELINE_LR = 1e-4\n",
        "NEW_LR = 1e-3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d576x3kUMxkT"
      },
      "outputs": [],
      "source": [
        "# Baseline model hyperparameters\n",
        "BASELINE_PARAMS = {\n",
        "    \"noise_dim\": NOISE_DIM,\n",
        "    \"batch_size\": BASELINE_BATCH_SIZE,\n",
        "    \"learning_rate\": BASELINE_LR\n",
        "}\n",
        "\n",
        "# New hyperparameters\n",
        "NEW_PARAMS = {\n",
        "    \"noise_dim\": NEW_NOISE_DIM,\n",
        "    \"batch_size\": NEW_BATCH_SIZE,\n",
        "    \"learning_rate\": NEW_LR\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsm3NPVJNxXo"
      },
      "outputs": [],
      "source": [
        "def make_generator_model(noise_dim):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7 * 7 * 256, use_bias = False, input_shape = (noise_dim,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-BLxJ7nOb6A"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqAzdjSYOlx1",
        "outputId": "6e339445-c2a8-449b-d97a-2ac51d6a4176"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sharh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "c:\\Users\\sharh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define discriminator and generator\n",
        "generator_baseline = make_generator_model(BASELINE_PARAMS[\"noise_dim\"])\n",
        "generator_new = make_generator_model(NEW_PARAMS[\"noise_dim\"])\n",
        "discriminator = make_discriminator_model()\n",
        "# Define optimizers\n",
        "generator_optimizer_baseline = tf.keras.optimizers.Adam(BASELINE_PARAMS[\"learning_rate\"])\n",
        "generator_optimizer_new = tf.keras.optimizers.Adam(NEW_PARAMS[\"learning_rate\"])\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(BASELINE_PARAMS[\"learning_rate\"])  # Same learning rate for discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTNPX492PSNP"
      },
      "outputs": [],
      "source": [
        "def generator_loss(fake_output):\n",
        "    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(fake_output), fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSDCtijtPkAY"
      },
      "outputs": [],
      "source": [
        "# Function to calculate discriminator loss\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLh-iSpqPuEA"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(images, generator, discriminator_optimizer, generator_optimizer):\n",
        "    baseline_noise_dim = BASELINE_PARAMS[\"noise_dim\"]\n",
        "    new_noise_dim = NEW_PARAMS[\"noise_dim\"]\n",
        "\n",
        "    #Generate noise tensors using the noise dimensions provided\n",
        "    baseline_noise= tf.random.normal([BASELINE_BATCH_SIZE, baseline_noise_dim])\n",
        "    new_noise= tf.random.normal([NEW_BATCH_SIZE, new_noise_dim])\n",
        "\n",
        "    #Select appropriate noise tensor\n",
        "    noise = baseline_noise if generator == generator_baseline else new_noise\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "\n",
        "      generated_images = generator(noise, training=True)\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qevyR3sYnnR_"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "train_step(train_images, generator_new, discriminator_optimizer, generator_optimizer_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNofQDxYN2GV"
      },
      "outputs": [],
      "source": [
        "#Define a checkpoint\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "# checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer_baseline, discriminator_optimizer=discriminator_optimizer, generator=generator_baseline,\n",
        "#                                  discriminator=discriminator)\n",
        "checkpoint = tf.train.Checkpoint()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Rq_Ap0Mdw2m"
      },
      "outputs": [],
      "source": [
        "def generate_and_save_images(generator, epoch, test_input, save_dir='images/'):\n",
        "  print(save_dir)\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = generator(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "  plt.savefig(os.path.join(save_dir, 'image_at_epoch_{:04d}.png'.format(epoch)))  # Save images in the specified directory\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dF0lKPcS3pO"
      },
      "outputs": [],
      "source": [
        "# Generate a random seed\n",
        "seed_baseline = tf.random.normal([16, BASELINE_PARAMS[\"noise_dim\"]])  # You can adjust the first dimension (16) as needed\n",
        "seed_new = tf.random.normal([16, NEW_PARAMS[\"noise_dim\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4j1e76MNiFM"
      },
      "outputs": [],
      "source": [
        "# Function to train the model\n",
        "def train(dataset, epochs, generator, discriminator, generator_optimizer, discriminator_optimizer, seed):\n",
        "    for num_epochs in epochs:\n",
        "        for epoch in range(num_epochs):\n",
        "            start = time.time()\n",
        "\n",
        "            for image_batch in dataset:\n",
        "                baseline_noise= tf.random.normal([BASELINE_BATCH_SIZE, BASELINE_PARAMS[\"noise_dim\"]])\n",
        "                new_noise= tf.random.normal([NEW_BATCH_SIZE, NEW_PARAMS[\"noise_dim\"]])\n",
        "                noise = baseline_noise if generator == generator_baseline else new_noise\n",
        "\n",
        "                train_step(image_batch, generator, discriminator_optimizer, generator_optimizer)\n",
        "                # Print generator and noise information\n",
        "                # print(\"Generator:\", generator)\n",
        "                # print(\"Noise shape:\", noise.shape)\n",
        "\n",
        "            # Update and display progress\n",
        "            display.clear_output(wait=True)\n",
        "            print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "            # Save the model every 15 epochs\n",
        "            if (epoch + 1) % 15 == 0:\n",
        "                checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "            # Save the model after 50 epochs\n",
        "            if (epoch + 1) == 50:\n",
        "                generate_and_save_images(generator, epoch + 1, seed)\n",
        "             # Print generator and noise information\n",
        "            print(\"Generator:\", generator)\n",
        "            print(\"Noise shape:\", noise.shape)\n",
        "\n",
        "  # Generate after the final epoch\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                           sum(epochs),\n",
        "                           seed)\n",
        "  #Save for each set of epochs\n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "#Create a TensorFlow dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BASELINE_BATCH_SIZE)\n",
        "\n",
        "#train with baseline hyperparameters\n",
        "train(train_dataset, [50], generator_baseline, discriminator, generator_optimizer_baseline, discriminator_optimizer, seed_baseline)\n",
        "#train with new hyperparameters\n",
        "train(train_dataset, [50], generator_new, discriminator, generator_optimizer_new, discriminator_optimizer, seed_new)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeHrGtSdw9Vv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}